# üîç My Deepfake Detection Benchmark Extension

This repository accompanies our research paper on **SAFE**. Our work is built upon and extends the [DeepfakeBench](https://github.com/SCLBD/DeepfakeBench) framework, aiming to explore more accurate and generalizable detection pipelines through **multi-modal alignment**, **curriculum learning**, and **LoRA-based fine-tuning** on CLIP-like backbones.

## üìÑ Paper Overview

* **Title**: *\[SAFE: Semantic- and Frequency-Enhanced Curriculum for Cross-Domain Deepfake Detection]*
* **Authors**: \[Yulin Yao, Kangfeng Zheng, Bin Wu, Jvjie Wang, Jiaqi Gao], et al.
* **Conference/Journal**: \[AAAI 2026]
* **Abstract**:
  \[Driven by advances in GANs and diffusion models, deepfake content has reached an unprecedented level of photorealism, causing detectors to deteriorate once they leave their training domain. Most prior studies adopt CLIP as the backbone of an image-level binary classifier, yet overlook CLIP‚Äôs core strength: text-to-image semantic alignment. Moreover, captions generated by CLIP-CAP lack sufficient high-level semantics to distinguish between authentic and manipulated faces. Deepfake generators often fail to maintain semantic coherence, resulting in contradictions that traditional visual models cannot capture. Existing approaches also intermingle all samples during training and thus lack a systematic, difficulty-aware curriculum. To bridge these gaps, we introduce Semantic- and Frequency-Enhanced (SAFE) deepfake detection, a two-component framework: 1) Semantic-enhanced multimodal alignment. Authenticity cues are injected into CLIP-CAP captions, and low-rank LoRA fine-tuning is applied to CLIP‚Äôs visual branch, yielding dual supervision for text‚Äìimage alignment and forgery discrimination. 2) Dual-score curriculum learning. Fourier Correlation Variance (FCV) measures local spectral consistency and, combined with the loss value, is transformed into a difficulty score that ranks training samples from easy to hard, reducing training time by 23.3\% and enhancing generalization. SAFE attains state-of-the-art performance on several cross-dataset and cross-manipulation benchmarks. Ablation studies confirm that semantic enhancement, LoRA fine-tuning, and dual-score curriculum are complementary, jointly delivering substantial gains in open-set generalization.]

## üß† Key Contributions

* üöß **Framework Extension**: Based on DeepfakeBench, we introduce additional modules supporting CLIP + LoRA finetuning and multi-modal representations.
* üîÅ **Curriculum Learning**: A progressive data sampling schedule is designed to improve robustness and generalization.
* üìù **Image-Text Alignment**: Inspired by recent multi-modal methods, we generate textual descriptions using ClipCap to guide representation learning.
* ‚öôÔ∏è **Lightweight Fine-tuning**: LoRA modules are selectively injected into the CLIP encoder, enabling efficient domain adaptation with minimal parameters.

## üóÇÔ∏è Datasets

We conduct experiments primarily on:

* [FF++](https://github.com/ondyari/FaceForensics) (FaceForensics++)
* [DFDC](https://ai.facebook.com/datasets/dfdc)
* [Celeb-DF](https://github.com/yuezunli/Celeb-DF)
* [DF40](https://github.com/YZY-stack/DF40)


## üöÄ Getting Started
1. Clone DeepfakeBench (required)
```
git clone https://github.com/SCLBD/DeepfakeBench
```
2. Install dependencies
Our environment requirements follow DeepfakeBench.
3. Clone this repository
```
https://github.com/kingkongs7/SAFE
```
4. Merge our files into deepfakebench
5. Training SAFE
The training script follows deepfakebench.
